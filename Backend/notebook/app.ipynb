{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "from flask_cors import CORS\n",
    "import param\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import requests\n",
    "from config import *\n",
    "\n",
    "# Define the Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Apply CORS to the entire app\n",
    "\n",
    "# Define the load_db function\n",
    "def load_db(folder_path, chain_type, k):\n",
    "    documents = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    api_key = OPENAI_API_KEY\n",
    "    persist_directory = PERSIST_DIRECTORY\n",
    "    embedding_function = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "    db = Chroma.from_documents(docs, embedding_function)\n",
    "    # db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "    llm_name = MODEL_NAME\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=llm_name, temperature=0, openai_api_key=api_key), \n",
    "        chain_type=chain_type, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "    )\n",
    "    return qa\n",
    "\n",
    "# Define the cbfs class and related functions\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query  = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "    \n",
    "    def __init__(self, **params):\n",
    "        super(cbfs, self).__init__( **params)\n",
    "        self.loaded_folder = \"docs/Chat\"\n",
    "        self.qa = load_db(self.loaded_folder, \"stuff\", 4)\n",
    "        self.chat_history = []\n",
    "        self.answer = \"\"\n",
    "        self.db_query = \"\"\n",
    "        self.db_response = []\n",
    "\n",
    "    def call_load_db(self, count):\n",
    "        if count == 0 or file_input.value is None:\n",
    "            return f\"Loaded File: {self.loaded_file}\"\n",
    "        else:\n",
    "            file_input.save(\"temp.pdf\")\n",
    "            self.loaded_file = file_input.filename\n",
    "            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
    "        self.clr_history()\n",
    "        return f\"Loaded File: {self.loaded_file}\"\n",
    "\n",
    "    def convchain(self, query, chat_history, qa):\n",
    "        if not query:\n",
    "             return {\"User\": \"\", \"ChatBot\": \"\"}\n",
    "\n",
    "        result = qa({\"question\": query, \"chat_history\": chat_history})\n",
    "        chat_history.extend([(query, result[\"answer\"])])\n",
    "        db_query = result[\"generated_question\"]\n",
    "        db_response = result[\"source_documents\"]\n",
    "        answer = result['answer']\n",
    "    \n",
    "        db_response_serializable = []\n",
    "        for doc in db_response:\n",
    "            doc_dict = {\n",
    "            \"title\": doc.title if hasattr(doc, \"title\") else \"Title not available\",\n",
    "            \"page_content\": doc.page_content if hasattr(doc, \"page_content\") else \"\"\n",
    "        }\n",
    "            db_response_serializable.append(doc_dict)\n",
    "\n",
    "        return {\n",
    "        \"User\": query,\n",
    "        \"ChatBot\": answer,\n",
    "        \"db_query\": db_query,\n",
    "        \"db_response\": db_response_serializable,\n",
    "        \"db_responses\": [doc.__dict__ for doc in db_response]\n",
    "    }\n",
    "\n",
    "\n",
    "    def clr_history(self, count=0):\n",
    "        self.chat_history = []\n",
    "\n",
    "# Instantiate the cbfs class\n",
    "cb = cbfs()\n",
    "\n",
    "@app.route(\"/ask\", methods=[\"POST\"])\n",
    "def ask():\n",
    "    data = request.get_json()\n",
    "    query = data[\"query\"]\n",
    "    chat_history = []\n",
    "\n",
    "    response = cb.convchain(query, chat_history, cb.qa)\n",
    "\n",
    "    response[\"query\"] = query\n",
    "\n",
    "    # Send the response to the Node.js server using requests.post()\n",
    "    nodejs_server_url = NODEJS_SERVER_URL\n",
    "    nodejs_response = requests.post(nodejs_server_url, json=response)  # Use requests.post() here\n",
    "\n",
    "    print(\"Response from convchain:\", response)\n",
    "\n",
    "    return jsonify(response)\n",
    "    data = request.get_json()\n",
    "    print(\"Received Data:\", data)  # Add this line to print the received data\n",
    "    if not data or \"files\" not in data:\n",
    "        return jsonify({\"error\": \"No files provided.\"}), 400\n",
    "\n",
    "    os.makedirs(target_directory, exist_ok=True)\n",
    "    responses = []\n",
    "\n",
    "    for file_info in data[\"files\"]:\n",
    "        file_content = file_info.get(\"content\", \"\")\n",
    "        if not file_content:\n",
    "            responses.append({\"error\": \"No file content provided.\"})\n",
    "            continue\n",
    "\n",
    "        file_name = os.path.basename(file_info[\"filePath\"])\n",
    "        file_path = os.path.join(target_directory, file_name)\n",
    "        \n",
    "        print(\"file_name\",file_name);\n",
    "        print(\"file_path\",file_path);\n",
    "\n",
    "        try:\n",
    "            with open(file_path, \"wb\") as f:  # Use \"wb\" for binary write mode\n",
    "                f.write(file_content)\n",
    "\n",
    "            responses.append({\"message\": f\"File '{file_name}' uploaded successfully.\"})\n",
    "        except Exception as e:\n",
    "            responses.append({\"error\": f\"Error uploading file '{file_name}': {str(e)}\"})\n",
    "\n",
    "    return jsonify(responses), 200\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
